{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f32a9bb2-96d1-4ce0-8b6b-3aec783797bb",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ccffcc; padding: 10px;\">\n",
    "    <h1> Tutorial 2 </h1>\n",
    "    <h2> Introduction to Modal Decomposition </h2>\n",
    "</div>\n",
    "\n",
    "# Overview\n",
    "\n",
    "This Jupyter notebook demonstrates how modal decomposition methods can be used for flow feature extraction in fluid mechanics datasets. Modal decomposition techniques, such as Proper Orthogonal Decomposition (POD) and Dynamic Mode Decomposition (DMD), help identify coherent structures in fluid flows, providing a useful dimension reduction for subsequent reduced order modelling. The example application focuses on the classic problem of fluid flow past a cylinder, showing how these methods can simplify complex flow fields into a manageable number of modes. This dimension reduction enables efficient and accurate reduced order modelling using Sparse Identification of Nonlinear Dynamics (SINDy).\n",
    "\n",
    "## Recommended reading\n",
    "\n",
    "* [Reduced order modelling](https://uk.mathworks.com/discovery/reduced-order-modeling.html)\n",
    "* [Dynamic Mode Decomposition (DMD) of numerical and experimental data](https://doi.org/10.1017/S0022112010001217)\n",
    "* [Proper Orthogonal Decomposition (POD) MIT notes](http://web.mit.edu/6.242/www/images/lec6_6242_2004.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980e4642-b64a-4fa0-a192-e8aada531472",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<div style=\"background-color: #e6ccff; padding: 10px;\">\n",
    "\n",
    "<h1> Machine Learning Theory </h1>\n",
    "\n",
    "# Modal Decomposition\n",
    "\n",
    "## The problem\n",
    "\n",
    "Flow feature extraction in fluid mechanics datasets involves identifying and characterizing significant patterns and structures within fluid flow data. This process is helpful for understanding complex flow behaviors, such as turbulence, vortex dynamics, and boundary layer interactions. By extracting these features, researchers can gain insights into the underlying physics of fluid flows and improve predictive models.\n",
    "\n",
    "Modal decomposition methods, such as Proper Orthogonal Decomposition (POD) and Dynamic Mode Decomposition (DMD), are powerful tools for flow feature extraction. These methods decompose complex flow fields into a set of orthogonal modes, each representing a distinct flow feature. By analyzing these modes, researchers can isolate and study specific flow phenomena, leading to a deeper understanding of fluid dynamics and more efficient data analysis.\n",
    "\n",
    "## Popular modal decomposition methods\n",
    "\n",
    "* Singular Value Decomposition (SVD): A fundamental linear algebra technique used to decompose a matrix into its singular values and vectors, often used in various modal analysis methods.\n",
    "* Proper Orthogonal Decomposition (POD): Also known as Principal Component Analysis (PCA) in statistics, POD identifies the most energetic modes in a flow field.\n",
    "* Dynamic Mode Decomposition (DMD): A method that decomposes complex systems into modes with specific temporal behaviors, useful for analyzing dynamic features in fluid flows.\n",
    "* Fourier Decomposition: Decomposes a signal into its constituent frequencies, often used for periodic or quasi-periodic flows.\n",
    "* Wavelet Decomposition: Provides a time-frequency representation of a signal, useful for analyzing transient and multi-scale phenomena in fluid flows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06222208-44db-4289-a21b-eb6f1ac25b70",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
    "\n",
    "# Python\n",
    "\n",
    "## [SciPy](https://scipy.org/)\n",
    "\n",
    "SciPy is a widely used open-source library for scientific and technical computing in Python. It builds on the NumPy array object and provides a large collection of algorithms and functions for numerical integration, optimization, signal processing, linear algebra, and more. SciPy enables users to perform complex scientific computations with ease and efficiency. With its intuitive Python interface, SciPy is accessible for beginners, yet it also offers advanced capabilities for experienced programmers. SciPy is compatible with various platforms, from personal computers to high-performance computing environments.\n",
    "\n",
    "## [PySINDy](https://github.com/dynamicslab/pysindy)\n",
    "\n",
    "PySINDy is a sparse regression package with several implementations for the Sparse Identification of Nonlinear Dynamical systems (SINDy) method introduced in Brunton et al. (2016a), including the unified optimization approach of Champion et al. (2019), SINDy with control from Brunton et al. (2016b), Trapping SINDy from Kaptanoglu et al. (2021), SINDy-PI from Kaheman et al. (2020), PDE-FIND from Rudy et al. (2017), and so on. A comprehensive literature review is given in de Silva et al. (2020) and Kaptanoglu, de Silva et al. (2021).\n",
    "\n",
    "## Further reading\n",
    "\n",
    "If you want to run this notebook locally or on a remote service:\n",
    "\n",
    "* [running Jupyter notebooks](https://jupyter.readthedocs.io/en/latest/running.html)\n",
    "* [installing the required Python environments](https://github.com/cemac/LIFD_ENV_ML_NOTEBOOKS/blob/main/howtorun.md)\n",
    "* [running the Jupyter notebooks locally](https://github.com/cemac/LIFD_ENV_ML_NOTEBOOKS/blob/main/jupyter_notebooks.md)\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a299542-e3b2-4f6c-898d-311a1614b0c5",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffffcc; padding: 10px;\">\n",
    "    \n",
    "<h1> Requirements </h1>\n",
    "\n",
    "This notebook should run with the following requirements satisfied.\n",
    "\n",
    "<h2> Python Packages: </h2>\n",
    "\n",
    "* numpy\n",
    "* scipy\n",
    "* matplotlib\n",
    "* notebook\n",
    "* pysindy\n",
    "* scikit-learn\n",
    "\n",
    "<h2> Data Requirements</h2>\n",
    "\n",
    "Required data from the fluid dynamics simulations are already included in the repository as `.npz` files.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ef9c77-4b31-451a-a388-1cc87aa111e7",
   "metadata": {},
   "source": [
    "**Contents:**\n",
    "\n",
    "1. [Overview and machine-learning theory](#Overview)\n",
    "2. [Singular Value Decomposition (SVD)](#Part-1:-SVD)\n",
    "3. [Proper Orthogonal Decomposition (POD)](#Part-2:-POD)\n",
    "4. [Dynamic Mode Decomposition (DMD)](#Part-3:-DMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e0a9a-0ab0-4952-8637-c09703fcb36d",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
    "\n",
    "## Import modules\n",
    "\n",
    "First we will import all the modules needed during this tutorial.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbe302a",
   "metadata": {},
   "source": [
    "### Note for Colab users\n",
    "\n",
    "If you are using Google Colab to run this notebook, you will need to download an additional module now by uncommenting and running the next code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ffcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/cemac/LIFD_ModalDecomposition/refs/heads/main/helper_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e56fa41",
   "metadata": {},
   "source": [
    "Let's import all the libraries we need. This may take a few seconds, depending on the speed of your filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21769fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_sample_image\n",
    "from helper_functions import download_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70558abb",
   "metadata": {},
   "source": [
    "## Part 1: SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f4f9b9",
   "metadata": {},
   "source": [
    "Let's start by reviewing the Singular Value Decomposition (SVD). The SVD is a powerful linear algebra technique that decomposes a matrix $\\mathbf{A}$ as $\\mathbf{A}=\\mathbf{U}\\boldsymbol{\\Sigma}\\mathbf{V}^H$, where $H$ denotes the Hermitian transpose. The column vectors of $\\mathbf{U}$ and $\\mathbf{V}$ are known as the left and right singular vectors, respectively. Denoting these column vectors as $\\mathbf{u}_j$ and $\\mathbf{v}_j$, we can also write the singular triplet $(\\mathbf{u}_j, \\mathbf{v}_j, \\sigma_j)$, where $\\sigma_j$ is $\\boldsymbol{\\Sigma}_{jj}$. The matrices $\\mathbf{U}$ and $\\mathbf{V}$ are unitary, meaning that $\\{\\mathbf{u}_j\\}_{j=0}$ and $\\{\\mathbf{v}_j\\}_{j=0}$ form orthogonal bases.\n",
    "\n",
    "By definition we then have that $\\mathbf{A}\\mathbf{v}_j=\\sigma_j\\mathbf{u}_j$, showing that the action of $\\mathbf{A}$ on any vector can be approximated well by the sum of a handful of vectors $\\mathbf{u}_j$ provided the singular values decay quickly. In other words, if we have the ordering $\\sigma_0>\\sigma_1>...$, then if $\\sigma_0\\gg\\sigma_1\\gg...$ the SVD can be used to create a low-rank approximation to $\\mathbf{A}$.\n",
    "\n",
    "To illustrate this, let's consider compressing an image.\n",
    "\n",
    "We first load an image of a flower, and rescale the integer red green blue (RGB) data to be floats between zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a flower image, and rescale the RGB channels to lie within [0, 1]\n",
    "flower = np.float32(load_sample_image('flower.jpg')/255)\n",
    "channels = ['red', 'green', 'blue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf15a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image: np.ndarray, ax=None, title=None):\n",
    "    \"\"\"\n",
    "    Plots an image from RGB data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------  \n",
    "    image: array with shape (number of pixels in y-direction,\n",
    "                             number of pixels in x-direction,\n",
    "                             channels).\n",
    "    ax: axis to plot the image in.\n",
    "    title: title for the plot.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4845a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(flower, title='Original image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f70c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of our image:', flower.shape)\n",
    "print('Memory of flower: %.2f MB ' % (np.prod(flower.shape)*32/1024/1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4a576",
   "metadata": {},
   "source": [
    "This image takes $427\\times640\\times3\\times\\textrm{size of  float}\\approx 25 ~\\mathrm{MB}$. Let's see if we can compress the image by retaining a low-rank approximation where only some of the singular values are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfbf108",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['red', 'green', 'blue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c083b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_reduced(image, rank=None):\n",
    "    \"\"\"\n",
    "    Return a low-rank approximation for an image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: array with shape (number of pixels in y-direction,\n",
    "                             number of pixels in x-direction,\n",
    "                             number of channels).\n",
    "    rank: How many dominant singular values to keep (default: all of them).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    reduced_image: A dictionary with size, red, green, and blue keys. The\n",
    "                   entry of size contains the shape of the image.\n",
    "                   Each channel (red, green, blue) entry is a tuple \n",
    "                   (U, Sigma, VH), such that our low rank approximation \n",
    "                   for that channel is U@Sigma@VH.\n",
    "    \"\"\"\n",
    "    reduced_image = {'size': image.shape}\n",
    "    if rank == None:\n",
    "        rank = np.min(image.shape[:2]) - 1\n",
    "    # Loop over RGB channels\n",
    "    for i, channel in enumerate(channels):\n",
    "        U, S, VH = sp.linalg.svds(flower[:, :, i], k=rank)\n",
    "        reduced_image[channel] = (U, S, VH)\n",
    "    return reduced_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_image(low_rank_image):\n",
    "    \"\"\"\n",
    "    Reconstructs the image from the low rank approximation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    low_rank_image: Low rank approximation obtained from image_reduced.\n",
    "    \"\"\"\n",
    "    # Reconstruct image\n",
    "    reconstructed_image = np.empty(shape=low_rank_image['size'], dtype=np.float32)\n",
    "    for i, channel in enumerate(channels):\n",
    "        (U, S, VH) = low_rank_image[channel]\n",
    "        reconstructed_image[:, :, i] = U @ np.diag(S) @ VH\n",
    "    return reconstructed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [1, 10, 40, 100]\n",
    "reduced_images = []\n",
    "for rank in ranks:\n",
    "    reduced_images.append(image_reduced(flower, rank=rank))\n",
    "fig, ax = plt.subplots(2, 2)\n",
    "for i, rank in enumerate(ranks):\n",
    "    image = reconstruct_image(reduced_images[i])\n",
    "    plot_image(image, ax=ax.flatten()[i], title=r'Rank=%d' % rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d72e3",
   "metadata": {},
   "source": [
    "From the above images we see that increasing the rank improves our low-rank approximation. Recall, that the full rank of the original image is 427. Despite this, even a rank 40 approximation is pretty good - albeit with some artifacts. At rank 100 the image is indistinguishable (at least to me). The memory requirement for a rank-100 approximation is 9.78 MB, significantly smaller than the original 25.02 MB image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_of_approximation(r):\n",
    "    \"\"\"\n",
    "    Returns the memory requirement for a rank-r approximation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    r: rank of approximation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mem: Memory in MB needed to store the approximation.\n",
    "    \"\"\"\n",
    "    # Have r floats, r vectors of size 427, r vectors of size 640 and 3 channels\n",
    "    mem = 3*((r*427) + (r*640) + r)*32/1024/1024\n",
    "    return mem\n",
    "\n",
    "print('Memory of rank 100 approximation %.2f MB ' % (memory_of_approximation(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025839fb",
   "metadata": {},
   "source": [
    "A more systematic way, than looking by eye, to gauge what rank is needed is to look at the singular values. We can do this by obtaining a full-rank approximation, and then adding up the singular values for each channel and normalising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b668a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_rank_full = image_reduced(flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66269e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the singular values\n",
    "svd_sum = 0\n",
    "for channel in channels:\n",
    "    (U, S, VH) = flower_rank_full[channel]\n",
    "    plt.semilogy(S[::-1]/np.max(S), color=channel)\n",
    "    svd_sum += S[::-1]\n",
    "# Normalise svd_sum\n",
    "svd_sum /= np.max(svd_sum)\n",
    "plt.semilogy(svd_sum, color='black')\n",
    "plt.grid(which='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_99 = np.argmax(svd_sum < 0.01)\n",
    "print(rank_99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44dd46",
   "metadata": {},
   "source": [
    "We see that the singular values drop off quickly, indicating that a low-rank approximation will be possible. A good rule of thumb is to set the rank such that the singular values have dropped to below 99% of the their maximum value. For the flower this obtained at 65."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1452ca",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Explore low-rank approximations for another image, e.g. `china.jpg`, in the scikit-image library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013c23d",
   "metadata": {},
   "source": [
    "## Part 2: POD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814804bc",
   "metadata": {},
   "source": [
    "So far we've seen that the SVD is able to capture the essence of a complicated dataset through reducing it to a low-rank approximation. Let's now consider the application of the SVD to fluid mechanics datasets. To this end, let's consider the classic example of flow past a cylinder (at Reynolds number 100). The dataset is stored on Hugging Face and can be downloaded with the `download_data` helper function. First, let's examine the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a203a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "download_data()\n",
    "data = np.load('data/cylinder_flow_data.npz')\n",
    "\n",
    "xu = data['xu']\n",
    "yu = data['yu']\n",
    "u = data['u']\n",
    "\n",
    "xv = data['xv']\n",
    "yv = data['yv']\n",
    "v = data['v']\n",
    "t = data['t']\n",
    "lift  = data['lift']\n",
    "lift_time  = data['lift_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a354745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lift_time[1:], lift[1:])\n",
    "plt.xlabel(r'$t$')\n",
    "plt.ylabel(r'Lift')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb314e3",
   "metadata": {},
   "source": [
    "Based on the above image, lets truncate our flow data to the vortex street which starts around $t=100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17085096",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = np.argmin(np.abs(t-300))\n",
    "u = u[t_start:]\n",
    "print(u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9445cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(xu, yu, u[-1], levels=40, cmap='plasma')\n",
    "plt.xlim([-1, 8])\n",
    "plt.ylim([-2, 2])\n",
    "plt.gca().set_aspect(True)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_bar = np.mean(u, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e151d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(xu, yu, u_bar, levels=40, cmap='plasma')\n",
    "plt.xlim([-1, 8])\n",
    "plt.ylim([-2, 2])\n",
    "plt.gca().set_aspect(True)\n",
    "plt.colorbar()\n",
    "plt.title('Mean flow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def POD(X, weight=None):\n",
    "    \"\"\"\n",
    "    Computes the POD using the method of snapshots.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: Snapshot matrix. Can be multidimensional, but time first be the last axis.\n",
    "    weight: Weight matrix for weighting the snapshots.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pod_modes: Matrix of pod_modes (space, mode_index).\n",
    "    eigenvaues: eigenvalues corresponding to the pod_modes.\n",
    "    \"\"\"\n",
    "    # Store the spatial shape\n",
    "    orig_shape = X.shape[:-1]\n",
    "    if X.ndim != 2:\n",
    "        # Must flatten spatial dimensions before SVD\n",
    "        X_snaps = X.reshape((np.prod(orig_shape), -1))\n",
    "    else:\n",
    "        X_snaps = X\n",
    "    # Form the covariance matrix\n",
    "    C = X_snaps.T @ X_snaps\n",
    "    # Perform the eigenvalue decompositions\n",
    "    eigval, eigvec = sp.linalg.eigs(C, k=24)\n",
    "    # Reconstruct the POD modes\n",
    "    pod_modes = X_snaps @ eigvec\n",
    "    # Make mode_index the first dimension\n",
    "    pod_modes = pod_modes.T\n",
    "    # Unflatten the spatial dimension\n",
    "    pod_modes = pod_modes.reshape((-1,) + orig_shape)\n",
    "    return eigval, pod_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a96a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "POD_data = (u-u_bar).transpose((1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3446e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigval, pod_modes = POD(POD_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b59da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pod_modes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a841eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(eigval/eigval[0], 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(xu, yu, pod_modes[0].real, levels=40, cmap='bwr')\n",
    "plt.xlim([-1, 8])\n",
    "plt.ylim([-2, 2])\n",
    "plt.gca().set_aspect(True)\n",
    "plt.colorbar()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57807766",
   "metadata": {},
   "source": [
    "## Part 3: DMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f63a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DMD_data = u.transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dfc22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DMD(snapshots, rank=10):\n",
    "    \"\"\"\n",
    "    Performs DMD on snapshot data, where time is the last axis\n",
    "    and snapshots are separated by a constant time interval.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    snapshots: Snapshot matrix. Can be multidimensional, but time first be the last axis.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    eigval: eigenvalues corresponding to the DMD_modes.\n",
    "    DMD_modes: Matrix of DMD_modes (space, mode_index).\n",
    "    \"\"\"\n",
    "    orig_shape = snapshots.shape[:-1]\n",
    "    if snapshots.ndim != 2:\n",
    "        snapshots_flattened = snapshots.reshape((np.prod(orig_shape), -1))\n",
    "    else:\n",
    "        snapshots_flattened = snapshots\n",
    "    X = snapshots_flattened[:,:-1]\n",
    "    Y = snapshots_flattened[:,1:]\n",
    "    U, S, VH = sp.linalg.svds(X, k=rank)\n",
    "    Abar = U.conj().T @ Y @ VH.conj().T @ np.diag(1/S)\n",
    "    eigval, eigvec = sp.linalg.eigs(Abar, k=rank)\n",
    "    DMD_modes = Y @ VH.conj().T @ np.diag(1/S) @ eigvec\n",
    "    DMD_modes = DMD_modes.T\n",
    "    DMD_modes = DMD_modes.reshape((-1,) + orig_shape)\n",
    "    return eigval, DMD_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55cdd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "e, m = DMD(POD_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "ax[0].plot(e.imag, e.real, 'x')\n",
    "ax[0].plot(np.cos(theta), np.sin(theta))\n",
    "ax[0].set_xlim([-1, 1])\n",
    "ax[0].set_ylim([-1, 1])\n",
    "ax[0].set_aspect('equal')\n",
    "\n",
    "mu = np.log(e)\n",
    "ax[1].plot(mu.imag, mu.real, 'x')\n",
    "ax[1].set_ylim([-0.1, 0.1])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f532fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(xu, yu, m[-1].real, levels=40, cmap='bwr')\n",
    "plt.xlim([-1, 8])\n",
    "plt.ylim([-2, 2])\n",
    "plt.gca().set_aspect(True)\n",
    "plt.colorbar()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ff5149-13ae-4153-8e77-51506b948f6c",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "   de Silva, Brian M., Kathleen Champion, Markus Quade,\n",
    "   Jean-Christophe Loiseau, J. Nathan Kutz, and Steven L. Brunton.\n",
    "   *PySINDy: a Python package for the sparse identification of\n",
    "   nonlinear dynamics from data.* arXiv preprint arXiv:2004.08424 (2020)\n",
    "   [arXiv](https://arxiv.org/abs/2004.08424)\n",
    "\n",
    "   Kaptanoglu, Alan A., Brian M. de Silva, Urban Fasel, Kadierdan Kaheman, Andy J. Goldschmidt\n",
    "   Jared L. Callaham, Charles B. Delahunt, Zachary G. Nicolaou, Kathleen Champion,\n",
    "   Jean-Christophe Loiseau, J. Nathan Kutz, and Steven L. Brunton.\n",
    "   *PySINDy: A comprehensive Python package for robust sparse system identification.*\n",
    "   arXiv preprint arXiv:2111.08481 (2021).\n",
    "   [arXiv](https://arxiv.org/abs/2111.08481)\n",
    "\n",
    "   Brunton, Steven L., Joshua L. Proctor, and J. Nathan Kutz.\n",
    "   *Discovering governing equations from data by sparse identification\n",
    "   of nonlinear dynamical systems.* Proceedings of the National\n",
    "   Academy of Sciences 113.15 (2016): 3932-3937.\n",
    "   [DOI](http://dx.doi.org/10.1073/pnas.1517384113)\n",
    "\n",
    "   Champion, K., Zheng, P., Aravkin, A. Y., Brunton, S. L., & Kutz, J. N. (2020).\n",
    "   *A unified sparse optimization framework to learn parsimonious physics-informed\n",
    "   models from data.* IEEE Access, 8, 169259-169271.\n",
    "   [DOI](https://doi.org/10.1109/ACCESS.2020.3023625)\n",
    "\n",
    "   Brunton, Steven L., Joshua L. Proctor, and J. Nathan Kutz.\n",
    "   *Sparse identification of nonlinear dynamics with control (SINDYc).*\n",
    "   IFAC-PapersOnLine 49.18 (2016): 710-715.\n",
    "   [DOI](https://doi.org/10.1016/j.ifacol.2016.10.249)\n",
    "\n",
    "   Kaheman, K., Kutz, J. N., & Brunton, S. L. (2020).\n",
    "   *SINDy-PI: a robust algorithm for parallel implicit sparse identification\n",
    "   of nonlinear dynamics.* Proceedings of the Royal Society A, 476(2242), 20200279.\n",
    "   [DOI](https://doi.org/10.1098/rspa.2020.0279)\n",
    "\n",
    "   Kaptanoglu, A. A., Callaham, J. L., Aravkin, A., Hansen, C. J., & Brunton, S. L. (2021).\n",
    "   *Promoting global stability in data-driven models of quadratic nonlinear dynamics.*\n",
    "   Physical Review Fluids, 6(9), 094401.\n",
    "   [DOI](https://doi.org/10.1103/PhysRevFluids.6.094401)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
